{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d2536a-cf8f-4e8c-85ca-f4dd069246e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Generator, use_deterministic_algorithms, randint, Tensor\n",
    "from functools import partial\n",
    "from typing import Tuple, Iterator\n",
    "\n",
    "from pathlib import Path\n",
    "from karpathy_series.makemore.data import read_data\n",
    "from karpathy_series.makemore.encoding.character import CharacterEncoder, CharacterSet, StringEncoder\n",
    "from karpathy_series.makemore.training.data import TrainingSequencer\n",
    "from karpathy_series.makemore.training.learning import Learner\n",
    "from karpathy_series.makemore.models.sequential import MPLNet, NGramNetGenerator\n",
    "from karpathy_series.makemore.bigrams import NGram\n",
    "\n",
    "%matplotlib inline\n",
    "use_deterministic_algorithms(True)\n",
    "generator = Generator()\n",
    "seed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ed41da-10b8-4381-8925-7d6835c3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../data/names.txt\")\n",
    "words = read_data(data_path)\n",
    "char_set = CharacterSet.from_words(words)\n",
    "char_encoder = CharacterEncoder.from_charset(char_set)\n",
    "string_encoder = StringEncoder(char_encoder)\n",
    "\n",
    "context_size = 4\n",
    "n_gram_gen = partial(NGram.generate, context_size, char_set.pad) \n",
    "ts = TrainingSequencer(string_encoder, char_encoder, n_gram_gen)\n",
    "\n",
    "embedding_dims = 10\n",
    "hidden_dims = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1d1758-79c5-4ee7-8139-de9b4756ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 4]) torch.Size([22655, 4]) torch.Size([22866, 4])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "xis_t, yis_t = ts.training_set(words[:n1])\n",
    "xis_d, yis_d = ts.training_set(words[n1:n2])\n",
    "xis_v, yis_v = ts.training_set(words[n2:])\n",
    "print(xis_t.shape, xis_d.shape, xis_v.shape)\n",
    "\n",
    "g = generator.manual_seed(seed)\n",
    "def batcher(batch: int, xs: Tensor, ys: Tensor) -> Iterator[Tuple[Tensor, Tensor]]:\n",
    "    length = xs.shape[0]\n",
    "    cover = length // batch\n",
    "    for _ in range(cover):\n",
    "        index = randint(0, length, (batch,), generator=g)\n",
    "        yield xs[index], ys[index]\n",
    "\n",
    "learning_sequence = partial(batcher, 100, xis_t, yis_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f42856-bb73-457d-9caf-f528130b7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator.manual_seed(seed)\n",
    "mpl_net = MPLNet.init_random_from_size(char_encoder.size, context_size, embedding_dims, hidden_dims, generator=g)\n",
    "generator = NGramNetGenerator(char_set, string_encoder, char_encoder, mpl_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fa4660-bb69-4c67-903b-ab570f211a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 is finished with loss = 2.350008010864258\n",
      "Epoch 2 is finished with loss = 2.147059440612793\n",
      "Epoch 3 is finished with loss = 2.352504014968872\n",
      "Epoch 4 is finished with loss = 2.4430510997772217\n",
      "Epoch 5 is finished with loss = 2.1677920818328857\n",
      "Epoch 6 is finished with loss = 1.9552032947540283\n",
      "Epoch 7 is finished with loss = 2.16409969329834\n",
      "Epoch 8 is finished with loss = 2.164581060409546\n",
      "Epoch 9 is finished with loss = 2.3554062843322754\n",
      "Epoch 10 is finished with loss = 2.0410265922546387\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(mpl_net, 0.01)\n",
    "learner(learning_sequence, epochs=10, report_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab7c9c3-125c-4771-b975-8bf75b52a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2019, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mpl_net.run(xis_v, yis_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836a6988-7b8b-480b-98eb-a81ffa826de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keensky\n",
      "anna\n",
      "kamari\n",
      "iishaner\n",
      "brin\n",
      "baserices\n",
      "adalyn\n",
      "mararin\n",
      "shana\n",
      "baie\n",
      "riannuah\n",
      "adur\n",
      "manna\n",
      "elio\n",
      "xopiyta\n",
      "kentir\n",
      "soviah\n",
      "zora\n",
      "nyca\n",
      "avyva\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(generator())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
