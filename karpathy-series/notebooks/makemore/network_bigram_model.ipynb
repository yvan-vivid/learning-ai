{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d2536a-cf8f-4e8c-85ca-f4dd069246e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib.pyplot import plot  # type: ignore\n",
    "from torch import manual_seed  # type: ignore\n",
    "\n",
    "from karpathy_series.makemore.bigrams import BiGram\n",
    "from karpathy_series.makemore.data import read_data\n",
    "from karpathy_series.makemore.encoding.character import CharacterEncoder, CharacterSet\n",
    "from karpathy_series.makemore.models.generation import BiGramNetGenerator\n",
    "from karpathy_series.makemore.models.linear import Linear\n",
    "from karpathy_series.makemore.models.perceptron import Perceptron\n",
    "from karpathy_series.makemore.training.data import TrainingSequencer\n",
    "from karpathy_series.makemore.training.learning import Learner, LearningRecord\n",
    "\n",
    "%matplotlib inline\n",
    "rand_source = manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81ed41da-10b8-4381-8925-7d6835c3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../data/names.txt\")\n",
    "words = read_data(data_path)\n",
    "char_set = CharacterSet.from_words(words)\n",
    "char_encoder = CharacterEncoder.from_charset(char_set)\n",
    "bi_gram_gen = partial(BiGram.generate, \".\")\n",
    "ts_bi = TrainingSequencer(char_encoder, char_encoder, bi_gram_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dde63a0c-76e1-47c0-88cf-2570a318e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear.init_random_from_size(char_encoder.size, char_encoder.size)\n",
    "generator = BiGramNetGenerator(char_set, char_encoder, linear)\n",
    "losses: LearningRecord = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "728967b6-3751-400d-9ab3-6886dc2e0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequence = ts_bi.training_sequence(words, 100, True)\n",
    "xis_v, yis_v = ts_bi.training_set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d3d0400-077e-4c83-a129-57f6ab48b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 is finished with loss = 2.502013921737671\n",
      "Epoch 20 is finished with loss = 2.3822524547576904\n",
      "Epoch 30 is finished with loss = 2.437615394592285\n",
      "Epoch 40 is finished with loss = 2.484553337097168\n",
      "Epoch 50 is finished with loss = 2.3631796836853027\n",
      "Epoch 60 is finished with loss = 2.453094005584717\n",
      "Epoch 70 is finished with loss = 2.3749213218688965\n",
      "Epoch 80 is finished with loss = 2.503520965576172\n",
      "Epoch 90 is finished with loss = 2.502284526824951\n",
      "Epoch 100 is finished with loss = 2.5687649250030518\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(linear, 10)\n",
    "losses += learner(training_sequence, epochs=100, report_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575d1c57-b7be-489f-96cc-bce44a0a95dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4573, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran = linear.run(xis_v, yis_v)\n",
    "ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a36b46-7c9d-4d65-814f-d2001c21e358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chabadayra'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = generator()\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcdf5ba-f865-4b67-94da-83f30febc65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot(\u001b[43mlosses\u001b[49m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot(losses)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e205a33-c7aa-431d-89bf-5119c779de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_layer = Perceptron.init_random_from_size(char_encoder.size, char_encoder.size, [300, 100])\n",
    "multi_layer_generator = BiGramNetGenerator(char_set, char_encoder, multi_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f144a46-5ab0-4b59-974e-9faa79b4f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_learner = Learner(multi_layer, 50)\n",
    "learned = m_learner(training_sequence, epochs=100, report_epochs=20)\n",
    "learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e22209-09b4-441c-9ee0-079892986f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = multi_layer_generator()\n",
    "generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
